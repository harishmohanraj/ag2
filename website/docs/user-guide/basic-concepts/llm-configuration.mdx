---
title: LLM configuration
---

Your AG2 agents are likely to need to use an LLM and you can configure one, or more, for each agent.

AG2's agents can use LLMs through OpenAI, Anthropic, Google, Amazon, Mistral AI, Cerebras, Together AI, and Groq. Locally hosted models can also be used through Ollama, LiteLLM, and LM Studio.

When creating your agents you'll set your LLM configuration:

```python
my_agent = ConversableAgent(
    name="helpful_agent",
    llm_config=llm_config,
    system_message="You are a poetic AI assistant",
)
```

If you would like to use a different provider, [see how here](https://docs.ag2.ai/docs/topics/non-openai-models/about-using-nonopenai-models).

### Environment variables

The examples in the Getting Started guide include an LLM configuration for OpenAI's `GPT-4o mini` model and will need the `OPENAI_API_KEY` environment variable set to your OpenAI API key.

Set it in your terminal/command prompt:

<Tabs>
  <Tab title="macOS / Linux">
    ```bash
    export OPENAI_API_KEY="your_api_key_here"
    ```
  </Tab>
  <Tab title="Windows">
    ```bash
    setx OPENAI_API_KEY "your_api_key_here"
    ```
  </Tab>
</Tabs>
